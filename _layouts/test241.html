
<!DOCTYPE html>
<html lang="en">
<head>
{% include head9.html %}
<title>three.js webgl - additive animation - skinning</title>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, user-scalable=yes, minimum-scale=1.0, maximum-scale=1.0">
<link type="text/css" rel="stylesheet" href="/main.css">
<link rel="stylesheet" href="/AssistBot.css" type="text/css">
<style>
body{font-family:Arial;font-size:14px;}
footer.copyright {padding: 0px !important;}
.closed{
width: 90px !important;
right: 230px !important;
}
.footer-wrap{height: 5px !important;}
.utc_textbox{display:inline-block;margin-top:7px;border:1px solid silver;width:150px;height:20px;font-family:Arial;font-size:14px;padding-left:4px;padding-right:4px;}
.utc_submitbox{display:inline-block;margin-top:7px;border:1px solid silver;height:23px;font-family:Arial;font-size:14px;}

a {
color: blue;
}
.control-inactive button {
color: #888;
}
</style>
<div id="container"></div>
<div id="info">

{% include header4c.html %}
</div>
</head>

<body>

<!-- Import maps polyfill -->
<!-- Remove this when import maps will be widely supported -->
<script async src="https://unpkg.com/es-module-shims@1.6.3/dist/es-module-shims.js"></script>

<script type="importmap">
{
"imports": {
"three": "../build/three.module.js",
"three/addons/": "./jsm/"
}
}
</script>

<script type="module">

import * as THREE from 'three';

import Stats from 'three/addons/libs/stats.module.js';

import { OrbitControls } from 'three/addons/controls/OrbitControls.js';
import { FBXLoader } from 'three/addons/loaders/FBXLoader.js';
import { GUI } from 'three/addons/libs/lil-gui.module.min.js';

THREE.ColorManagement.enabled = true;

let camera, scene, renderer, stats, object;
let model, skeleton, currentBaseAction, prepareCrossFade, idle,animations, walk, idle4;
const crossFadeControls = [];

//	let currentBaseAction = 'idle';
const animationActions = []
const allActions = [];
const baseActions = {
//idle: { weight: 1 },
//walk: { weight: 0 },
//run: { weight: 0 }
};
const additiveActions = {
sneak_pose: { weight: 0 },
sad_pose: { weight: 0 },
agree: { weight: 0 },
"will2|headShake_will2": { weight: 0 }
};
let panelSettings, numAnimations;

const clock = new THREE.Clock();

let mixer;

init();
animate();

function init() {

const container = document.createElement( 'div' );
document.body.appendChild( container );

camera = new THREE.PerspectiveCamera( 45, window.innerWidth / window.innerHeight, 1, 2000 );
camera.position.set( 100, 200, 300 );

scene = new THREE.Scene();
scene.background = new THREE.Color( 0xa0a0a0 );
//scene.fog = new THREE.Fog( 0xa0a0a0, 200, 1000 );

const hemiLight = new THREE.HemisphereLight( 0xffffff, 0x444444, 0.5 );
hemiLight.position.set( 0, 200, 0 );
scene.add( hemiLight );

const dirLight = new THREE.DirectionalLight( 0xffffff, 0.5 );
dirLight.position.set( 0, 200, 100 );
dirLight.castShadow = true;
dirLight.shadow.camera.top = 180;
dirLight.shadow.camera.bottom = - 100;
dirLight.shadow.camera.left = - 120;
dirLight.shadow.camera.right = 120;
scene.add( dirLight );

// scene.add( new THREE.CameraHelper( dirLight.shadow.camera ) );

// ground
var textureLoader = new THREE.TextureLoader();
var skirt = textureLoader.load('/assets/glb/textures/skirt.png');
var head = textureLoader.load('/assets/glb/textures/Std_Skin_Head_Diffuse.jpg');
var body = textureLoader.load('/assets/glb/textures/Std_Skin_Body_Diffuse.jpg');
var arm = textureLoader.load('/assets/glb/textures/Std_Skin_Arm_Diffuse.jpg');
var leg = textureLoader.load('/assets/glb/textures/Std_Skin_Leg_Diffuse.jpg');
var nails = textureLoader.load('/assets/glb/textures/Std_Nails_Diffuse.jpg');
var eyelash = textureLoader.load('/assets/glb/textures/Std_Eyelash_Diffuse.jpg');
var hair = textureLoader.load('/assets/glb/textures/Hair_Diffuse.png');
var tearR = textureLoader.load('/assets/glb/textures/Std_Tearline_R_Diffuse.jpg');
var tearL = textureLoader.load('/assets/glb/textures/Std_Tearline_L_Diffuse.jpg');
var tongue = textureLoader.load('/assets/glb/textures/Std_Tongue_Diffuse.png');
var upper = textureLoader.load('/assets/glb/textures/Std_Upper_Teeth_Diffuse.png');
var lower = textureLoader.load('/assets/glb/textures/Std_Lower_Teeth_Diffuse.png');
var hair01 = textureLoader.load('/assets/glb/textures/Hair_Diffuse_0001.png');
var corneaL = textureLoader.load('/assets/glb/textures/Std_Cornea_L_Diffuse.png');
var eyeL = textureLoader.load('/assets/glb/textures/Std_Eye_L_Diffuse.png');
var corneaR = textureLoader.load('/assets/glb/textures/Std_Cornea_R_Diffuse.png');
var eyeR = textureLoader.load('/assets/glb/textures/Std_Eye_R_Diffuse.png');
var eyeRO = textureLoader.load('/assets/glb/textures/Std_Eye_Occlusion_R_Diffuse.jpg');
var eyeLO = textureLoader.load('/assets/glb/textures/Std_Eye_Occlusion_L_Diffuse.jpg');
var hair02 = textureLoader.load('/assets/glb/textures/Hair_Transparency_Diffuse.png');
var scalp = textureLoader.load('/assets/glb/textures/Scalp_Transparency_Diffuse.jpg');
var hair02Material = new THREE.MeshPhongMaterial({map:hair02});
var eyeLOMaterial = new THREE.MeshPhongMaterial({map:eyeLO});
var eyeROMaterial = new THREE.MeshPhongMaterial({map:eyeRO});
var eyeLMaterial = new THREE.MeshPhongMaterial({map:eyeL});
var corneaLMaterial = new THREE.MeshPhongMaterial({map: corneaL});
var eyeRMaterial = new THREE.MeshPhongMaterial({map:eyeR});
var corneaRMaterial = new THREE.MeshPhongMaterial({map: corneaR});
var lowerMaterial = new THREE.MeshPhongMaterial({map: lower});
var upperMaterial = new THREE.MeshPhongMaterial({map: upper});
var tongueMaterial = new THREE.MeshPhongMaterial({map: tongue});
var skirtMaterial = new THREE.MeshPhongMaterial({map: skirt});
var tearLMaterial = new THREE.MeshPhongMaterial({map: tearL});
var tearRMaterial = new THREE.MeshPhongMaterial({map: tearR});
var bodyMaterial = new THREE.MeshPhongMaterial({map: body});
var headMaterial = new THREE.MeshPhongMaterial({map: head});
var armMaterial = new THREE.MeshPhongMaterial({map: arm});
var legMaterial = new THREE.MeshPhongMaterial({map: leg});
var nailMaterial = new THREE.MeshPhongMaterial({map: nails});
var eyelashMaterial = new THREE.MeshPhongMaterial({map: eyelash});
var hairMaterial = new THREE.MeshPhongMaterial({map: hair});
var hair01Material = new THREE.MeshPhongMaterial({map: hair01});
var scalpMaterial = new THREE.MeshPhongMaterial({map: scalp});
const mesh = new THREE.Mesh( new THREE.PlaneGeometry( 2000, 2000 ), new THREE.MeshPhongMaterial( { color: 0x999999, depthWrite: false } ) );
mesh.rotation.x = - Math.PI / 2;
mesh.receiveShadow = true;
scene.add( mesh );

const grid = new THREE.GridHelper( 2000, 20, 0x000000, 0x000000 );
grid.material.opacity = 0.2;
grid.material.transparent = true;
scene.add( grid );

// model

const loader = new FBXLoader();
loader.load( 'assets/glb/dude45d.fbx', function ( object ) {

mixer = new THREE.AnimationMixer( object );

const clips = object.animations;
clips[1] = idle4; 
//folder1.add(idle4, 0,1);

const idle = mixer.clipAction( clips[ 2 ] );
const walk = mixer.clipAction( clips[ 2 ] );
const sneak_pose = mixer.clipAction( clips[ 2 ] );
const sad_pose = mixer.clipAction( clips[ 2 ] );
const headShake = mixer.clipAction( clips[ 2 ] );
const agree = mixer.clipAction( clips[ 2 ] );
const run = mixer.clipAction( clips[ 2 ] );

function buttonFunction4() {
//const action = mixer.clipAction( clips[ 2 ] );
action1.play();
}
var params4 = {
None: buttonFunction4
};

folder1.add(params4, 'None');

function buttonFunction1() {
//const action = mixer.clipAction( clips[ 2 ] );
action1.play();
}
var params1 = {
run: buttonFunction1
};

folder1.add(params1, 'run');

function buttonFunction2() {
action1.fadeOut (0.3);
action1.stop(1);
const action = mixer.clipAction( clips[ 2 ] );
action2.play();
}
var params2 = {
walk: buttonFunction2
};

folder1.add(params2, 'walk');

function buttonFunction3() {
action1.fadeOut (0.3);
action1.stop(1);
const action = mixer.clipAction( clips[ 2 ] );
action2.play();
}
var params3 = {
idle: buttonFunction3
};

folder1.add(params3, 'idle');

// Update the mixer on each frame
function update () {
mixer.update( deltaSeconds );
}

// Play a specific animation
//idle = object.animations[8];
//		walk = object.animations[2];

//const action = mixer.clipAction( object.animations[ 8 ] );
//action.play();


//let currentBaseAction = object.animations[ 8 ];

object.traverse( function ( child ) {

if ( child.isMesh ) {
if ( child.name == "CC_Base_Body"){
// child.material[0] = skirtMaterial;
// child.material[1] = scalpMaterial;
// child.material[2] = hair02Material;
// child.material[3] = eyeROMaterial;
// child.material[4] = eyeLOMaterial;
// child.material[5] = eyeRMaterial;
// child.material[6] = corneaRMaterial;
// child.material[7] = eyeLMaterial;
// child.material[8] = corneaLMaterial;
// child.material[9] = hairMaterial;
child.material[0] = headMaterial;
child.material[1] = bodyMaterial;
child.material[2] = armMaterial;
child.material[3] = legMaterial;
child.material[4] = nailMaterial;
child.material[5] = eyelashMaterial;
// child.material[16] = tearRMaterial;
// child.material[17] = tearLMaterial;
// child.material[18] = tongueMaterial;
// child.material[19] = upperMaterial;
//child.material[20] = lowerMaterial;
//child.material[21] = hair01Material;
console.log('working'); 
};

if ( child.name == "Double_high"){
child.material[0] = scalpMaterial;
child.material[1] = hair02Material;


};

if ( child.name == "CC_Base_EyeOcclusion"){
child.material[0] = eyeROMaterial;
child.material[1] = eyeLOMaterial;

};

if ( child.name == "CC_Base_Teeth"){
child.material[0] = upperMaterial;
child.material[1] = lowerMaterial;

};
if ( child.name == "A7_0310001"){
child.material[0] = hairMaterial;
child.material[1] = hairMaterial;
};
if ( child.name == "A7_0310"){
child.material[0] = hairMaterial;
child.material[1] = hair01Material;
};

if ( child.name ==  "CC_Base_Eye"){
child.material[0] = eyeRMaterial;
child.material[1] = corneaRMaterial;
child.material[2] = eyeLMaterial;
child.material[3] = corneaLMaterial;
};

if ( child.name == "CC_Base_TearLine"){
child.material[16] = tearRMaterial;
child.material[17] = tearLMaterial;
};
if ( child.name == "CC_Base_Tongue"){
child.material[0] = tongueMaterial;
}
child.castShadow = true;
child.receiveShadow = true;

}

} );


scene.add( object );
console.log(object); 

} );

renderer = new THREE.WebGLRenderer( { antialias: true } );
renderer.setPixelRatio( window.devicePixelRatio );
renderer.setSize( window.innerWidth, window.innerHeight );
renderer.outputEncoding = THREE.sRGBEncoding;
renderer.shadowMap.enabled = true;
container.appendChild( renderer.domElement );

const controls = new OrbitControls( camera, renderer.domElement );
controls.target.set( 0, 100, 0 );
controls.update();

//webkitURL is deprecated but nevertheless
URL = window.URL || window.webkitURL;

var gumStream; 						//stream from getUserMedia()
var rec; 							//Recorder.js object
var input; 							//MediaStreamAudioSourceNode we'll be recording

// shim for AudioContext when it's not avb. 
var AudioContext = window.AudioContext || window.webkitAudioContext;
var audioContext //audio context to help us record

var recordButton = document.getElementById("recordButton");
var stopButton = document.getElementById("stopButton");
var pauseButton = document.getElementById("pauseButton");


//add events to those 2 buttons
recordButton.addEventListener("click", startRecording);

stopButton.addEventListener("click", stopRecording);
pauseButton.addEventListener("click", pauseRecording);

var scrollTimer = -1;


var voice = {
  // (A) INIT SPEECH RECOGNITION
  sform : null, // html search form
  sfield : null, // html search field
  sbtn : null, // html voice search button
  recog : null, // speech recognition object
  init : () => {
    // (A1) GET HTML ELEMENTS
    voice.sfrom = document.getElementById("search-form");
    voice.sfield = document.getElementById("search-field");
    voice.sbtn = document.getElementById("search-speech");
 
    // (A2) GET MICROPHONE ACCESS
    navigator.mediaDevices.getUserMedia({ audio: true })
    .then(stream => {
      // (A3) SPEECH RECOGNITION OBJECT + SETTINGS
      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
      voice.recog = new SpeechRecognition();
      voice.recog.lang = "en-US";
      voice.recog.continuous = false;
      voice.recog.interimResults = false;
 
      // (A4) POPUPLATE SEARCH FIELD ON SPEECH RECOGNITION
      voice.recog.onresult = evt => {
        let said = evt.results[0][0].transcript.toLowerCase();
        voice.sfield.value = said;
        
        // voice.sform.submit();
        // OR RUN AN AJAX/FETCH SEARCH
        voice.stop();
        console.log(said);
        
        const xhr = new XMLHttpRequest();
xhr.open("GET", `https://seal-app-qvihb.ondigitalocean.app/test123/${said}`);
xhr.send();
xhr.responseType = "json";
xhr.onload = () => {
  if (xhr.readyState == 4 && xhr.status == 200) {
    console.log(xhr.response);
  //  console.log(xhr.response.traits.text[0].value);
    var obj = xhr.response;
		console.log(JSON.stringify(obj.traits));
		var objlength = JSON.stringify(obj.traits);
        var obj1q = JSON.stringify(xhr.response);
        if (objlength.length < 3) {
		var objecttext = "I'm sorry, but I didn't understand the question. Please try again";
		console.log(objecttext+'dfgdfgdfgdfgdgdgdgdgf'); 
        }else { var objecttext = obj.traits.text[0].value};
        const listener = new THREE.AudioListener();
		camera.add( listener );
		const sound = new THREE.Audio( listener );
		const audioLoader = new THREE.AudioLoader();
		audioLoader.load( `https://orca-app-4xcdq.ondigitalocean.app/?text=${objecttext}`, function( buffer ) {
		sound.setBuffer( buffer );
		sound.setLoop( false );
		sound.setVolume( 0.5 );
		sound.play();
		const analyser1 = new THREE.AudioAnalyser( sound, 32 );
		}); 
  } else {
    console.log(`Error: ${xhr.status}`);
  }
};


      };
 
      // (A5) ON SPEECH RECOGNITION ERROR
      voice.recog.onerror = err => console.error(err);
 
      // (A6) READY!
      voice.sbtn.disabled = false;
      voice.stop();
    })
    .catch(err => {
      console.error(err);
      voice.sbtn.value = "Please enable access and attach microphone.";
    });
  },
 
  // (B) START SPEECH RECOGNITION
  start : () => {
    voice.recog.start();
    voice.sbtn.onclick = voice.stop;
    const sample = document.getElementById("search-speech");
    sample.style.background = `url('https://api.iconify.design/ph/microphone-fill.svg?color=red&height=24') center no-repeat`; 
    voice.sbtn.value = "";
  },
 
  // (C) STOP/CANCEL SPEECH RECOGNITION
  stop : () => {
    voice.recog.stop();
    voice.sbtn.onclick = voice.start;
    const sample = document.getElementById("search-speech");
    sample.style.background = `url('https://api.iconify.design/ph/microphone-fill.svg?color=black&height=24') center no-repeat`; 
    
    voice.sbtn.value = "";
  }
};
window.addEventListener("DOMContentLoaded", voice.init);



window.addEventListener('scroll',(event) => {
    console.log('Scrolling...');
	if (scrollTimer != -1)
        clearTimeout(scrollTimer);
		const t = clock.getElapsedTime();
		animate();
//		skeletonHelper.bones[18].rotation.x = Math.sin( t ) * 10.005;
//		skeletonHelper.bones[3].rotation.x = Math.sin( t ) * 10.005;
		/*	
		if(skeletonHelper.bones[18].rotation.x = -8.476002064288632){
			skeletonHelper.bones[18].rotation.x = Math.sin( t ) * 10.005;
		}

		if(skeletonHelper.bones[18].rotation.x = -2.8845221741125893){
			skeletonHelper.bones[18].rotation.x = Math.sin( t ) * -10.005;
		}


		if(skeletonHelper.bones[3].rotation.x = 2.8845221741125893){
			skeletonHelper.bones[3].rotation.x = Math.sin( t ) * 10.005;
		}

		if(skeletonHelper.bones[3].rotation.x = 8.11028946105655){
			skeletonHelper.bones[3].rotation.x = Math.sin( t ) * -10.005;
		}
	
		skeletonHelper.bones[74].rotation.y = Math.sin( t ) * -10.005;
		skeletonHelper.bones[102].rotation.y = Math.sin( t ) * -10.005;
*/
      scrollTimer = window.setTimeout(scrollFinished(), 5000);
    }
);

function scrollFinished() {
      console.log('Scroll Finished')
    };

	function scrollStop (callback, refresh = 66) {

		

// Make sure a valid callback was provided
if (!callback || typeof callback !== 'function') return;

// Setup scrolling variable
let isScrolling;



// Listen for scroll events
window.addEventListener('scroll', function (event) {

	// Clear our timeout throughout the scroll
	window.clearTimeout(isScrolling);

	// Set a timeout to run after scrolling ends
	isScrolling = setTimeout(callback, refresh);

}, false);

}

scrollStop(function () {
	
console.log('Scrolling has stopped.');
console.log(skeletonHelper.bones[18].rotation.x);
console.log(skeletonHelper.bones[3].rotation.x);
//skeletonHelper.bones[18].rotation.x = -3.0006409159284159933;
//skeletonHelper.bones[3].rotation.x = 3.0006409159284159933;
//skeletonHelper.bones[74].rotation.y = 0;
//skeletonHelper.bones[102].rotation.y = 0;
});

function pauseRecording(){
	console.log("pauseButton clicked rec.recording=",rec.recording );
	if (rec.recording){
		//pause
		rec.stop();
		pauseButton.innerHTML="Resume";
	}else{
		//resume
		rec.record()
		pauseButton.innerHTML="Pause";

	}
}

function server5(){
	console.log(camera);
}

if (navigator.mediaDevices.getUserMedia) {
	console.log('getUserMedia supported.');

	const constraints = { audio: true };
  let chunks = [];
  let onSuccess = function(stream) {
    const mediaRecorder = new MediaRecorder(stream);

	recordButton.addEventListener("click", recorde);
	stopButton.addEventListener("click", stop1);

     function recorde() {
      mediaRecorder.start();
      console.log(mediaRecorder.state);
      console.log("recorder started");
     // record.style.background = "red";

      //stop.disabled = false;
     // record.disabled = true;
    }

    function stop1() {
      mediaRecorder.stop();
      console.log(mediaRecorder.state);
      console.log("recorder stopped");
     // record.style.background = "";
    //  record.style.color = "";
      // mediaRecorder.requestData();

      stop.disabled = true;
      //record.disabled = false;
    }

    mediaRecorder.onstop = function(e) {
      console.log("data available after MediaRecorder.stop() called.");

      const clipName = prompt('Enter a name for your sound clip?','My unnamed clip');

      const clipContainer = document.createElement('article');
      const clipLabel = document.createElement('p');
      const audio = document.createElement('audio');
      const deleteButton = document.createElement('button');

      clipContainer.classList.add('clip');
      audio.setAttribute('controls', '');
      deleteButton.textContent = 'Delete';
      deleteButton.className = 'delete';

      if(clipName === null) {
        clipLabel.textContent = 'My unnamed clip';
      } else {
        clipLabel.textContent = clipName;
      }

      clipContainer.appendChild(audio);
      clipContainer.appendChild(clipLabel);
      clipContainer.appendChild(deleteButton);
      soundClips.appendChild(clipContainer);

      audio.controls = true;
      const blob = new Blob(chunks, { 'type' : 'audio/wav; codecs=opus' });
      chunks = [];
      const audioURL = window.URL.createObjectURL(blob);
	  var url = URL.createObjectURL(blob);
	  var au = document.createElement('audio');
	var li = document.createElement('li');
	var link = document.createElement('a');

	//name of .wav file to use during upload and download (without extendion)
	var filename = new Date().toISOString();

//	//add controls to the <audio> element
//	au.controls = true;
//	au.src = url;

	//save to disk link
	link.href = url;
	link.download = filename+".wav"; //download forces the browser to donwload the file using the  filename
	link.innerHTML = "Save to disk";
      audio.src = audioURL;
	  var fd=new FormData();
	  var xhr=new XMLHttpRequest();
	fd.append("file",blob, filename);	
	// WARNING: For POST requests, body is set to null by browsers.
var data = new FormData();
data.append("file", blob, filename);
 
xhr.withCredentials = false;

xhr.addEventListener("readystatechange", function() {
  if(this.readyState === 4) {
    console.log(this.responseText);
  }
});
 // create a blob here for testing
 var blob1 = new Blob(["i am a blob"]);
 
    //var blob = yourAudioBlobCapturedFromWebAudioAPI;// for example   
    var reader = new FileReader();
    // this function is triggered once a call to readAsDataURL returns
    reader.onload = function(event){
        var fd = new FormData();
		
       fd.append("file", blob);
        $.ajax({
            type: 'POST',
            url: 'https://sea-turtle-app-w6yax.ondigitalocean.app/read4',
            data: fd,
            processData: false,
            contentType: false
        }).done(function(data) {
            // print the output from the upload.php script
            console.log(data);
        });
    };      
    // trigger the read from the reader...
    reader.readAsDataURL(blob1);
/*xhr.open("POST", "https://sea-turtle-app-w6yax.ondigitalocean.app/read4", true);
xhr.setRequestHeader('Access-Control-Allow-Origin', '*');
	xhr.setRequestHeader("Access-Control-Allow-Methods","PUT, GET, POST, DELETE, OPTIONS");
	xhr.setRequestHeader("Access-Control-Allow-Headers","Special-Request-Header, Origin, X-Requested-With, Content-Type, Accept, Authorization");
	xhr.setRequestHeader('Access-Control-Allow-Credentials', 'true');
	xhr.setRequestHeader('Access-Control-Max-Age', '240');
xhr.send(data);
	xhr.open("POST","{{ site.apilink3 }}",true);
	xhr.setRequestHeader('Access-Control-Allow-Origin', '*');
	xhr.setRequestHeader("Access-Control-Allow-Methods","PUT, GET, POST, DELETE, OPTIONS");
	xhr.setRequestHeader("Access-Control-Allow-Headers","Special-Request-Header, Origin, X-Requested-With, Content-Type, Accept, Authorization");
	xhr.setRequestHeader('Access-Control-Allow-Credentials', 'true');
	xhr.setRequestHeader('Access-Control-Max-Age', '240');
	xhr.send(data);*/


	var formdata = new FormData();
formdata.append("file", blob, "microphone-recording4.wav");

	var requestOptions = {
  method: 'POST',
  body: formdata,
  redirect: 'follow'
};


      console.log("recorder stopped");
	  console.log(audioURL);

      deleteButton.onclick = function(e) {
        e.target.closest(".clip").remove();
      }

      clipLabel.onclick = function() {
        const existingName = clipLabel.textContent;
        const newClipName = prompt('Enter a new name for your sound clip?');
        if(newClipName === null) {
          clipLabel.textContent = existingName;
        } else {
          clipLabel.textContent = newClipName;
        }
      }
    }

    mediaRecorder.ondataavailable = function(e) {
      chunks.push(e.data);
    }
  }
  let onError = function(err) {
    console.log('The following error occured: ' + err);
  }

  navigator.mediaDevices.getUserMedia(constraints).then(onSuccess, onError);

}else {
   console.log('getUserMedia not supported on your browser!');
}


function startRecording() {
	console.log("recordButton clicked");
	document.getElementById("stopButton").style.display = 'block';
	document.getElementById('recordButton').style.display = 'none';
	/*
		Simple constraints object, for more advanced audio features see
		https://addpipe.com/blog/audio-constraints-getusermedia/
	*/
    
    var constraints = { audio: true, video:false }

 	/*
    	Disable the record button until we get a success or fail from getUserMedia() 
	*/

	recordButton.disabled = false;
	stopButton.disabled = false;
	pauseButton.disabled = false

	/*
    	We're using the standard promise based getUserMedia() 
    	https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices/getUserMedia
	*/

	navigator.mediaDevices.getUserMedia(constraints).then(function(stream) {
		console.log("getUserMedia() success, stream created, initializing Recorder.js ...");

		/*
			create an audio context after getUserMedia is called
			sampleRate might change after getUserMedia is called, like it does on macOS when recording through AirPods
			the sampleRate defaults to the one set in your OS for your playback device

		*/
		audioContext = new AudioContext();

		//update the format 
		document.getElementById("formats").innerHTML="Format: 1 channel pcm @ "+audioContext.sampleRate/1000+"kHz"

		/*  assign to gumStream for later use  */
		gumStream = stream;
		
		/* use the stream */
		input = audioContext.createMediaStreamSource(stream);

		/* 
			Create the Recorder object and configure to record mono sound (1 channel)
			Recording 2 channels  will double the file size
		*/
		rec = new Recorder(input,{numChannels:1})

		//start the recording process
		rec.record()

		console.log("Recording started");

	}).catch(function(err) {
	  	//enable the record button if getUserMedia() fails
    	recordButton.disabled = false;
    	stopButton.disabled = false;
    	pauseButton.disabled = true
	});
}


function stopRecording() {
	console.log("stopButton clicked");
	//console.log(window.e.head);;
	console.log(window);
	document.getElementById("recordButton").style.display = 'block';
	document.getElementById('stopButton').style.display = 'none';
	//disable the stop button, enable the record too allow for new recordings
	stopButton.disabled = false;
	recordButton.disabled = false;
	pauseButton.disabled = true;

	//reset button just in case the recording is stopped while paused
	pauseButton.innerHTML="Pause";
	
	//tell the recorder to stop the recording
//	rec.stop();

	//stop microphone access
	//gumStream.getAudioTracks()[0].stop();

	//create the wav blob and pass it on to createDownloadLink
	//rec.exportWAV(createDownloadLink);
}

function createDownloadLink(blob) {
	
	var url = URL.createObjectURL(blob);
	var au = document.createElement('audio');
	var li = document.createElement('li');
	var link = document.createElement('a');

	//name of .wav file to use during upload and download (without extendion)
	var filename = new Date().toISOString();

	//add controls to the <audio> element
	au.controls = true;
	au.src = url;

	//save to disk link
	link.href = url;
	link.download = filename+".wav"; //download forces the browser to donwload the file using the  filename
	link.innerHTML = "Save to disk";

	//add the new audio element to li
	li.appendChild(au);
	
	//add the filename to the li
	li.appendChild(document.createTextNode(filename+".wav "))

	//add the save to disk link to li
	li.appendChild(link);
	
	//upload link
	var upload = document.createElement('a');
	upload.href="#";
	upload.innerHTML = "Upload";
	var xhr=new XMLHttpRequest();
	xhr.onload=function(e) {
		if(this.readyState === 4) {
			console.log("Server returned: ",e.target.responseText);
			const text99 = JSON.parse(e.target.responseText);
			var userMessage = document.querySelector("#userInput").value;
      let userHtml = '<div class="d-flex justify-content-end mb-4">'+'<div class="msg_cotainer_send">'+text99.transcript+'</div>'+image1+'</div>';
      document.querySelector('#body').innerHTML+= userHtml;
	  let xhr = new XMLHttpRequest();
      xhr.open(`GET`, `{{ site.apilink1 }}${text99.transcript}`);
      xhr.setRequestHeader("Content-type", "application/x-www-form-urlencoded");
      xhr.send(`messageValue=${text99.transcript}`);
	  xhr.onload = function () {
		var obj = JSON.parse(this.responseText);
		console.log(JSON.stringify(obj.traits));
		var objlength = JSON.stringify(obj.traits);
		var obj1q = JSON.stringify(this.responseText);
		if (objlength.length < 3) {
		var objecttext = "I'm sorry, but I didn't understand the question. Please try again";
		console.log(objecttext+'dfgdfgdfgdfgdgdgdgdgf'); 
		}else { var objecttext = obj.traits.text[0].value};
		let botHtml = '<div class="d-flex justify-content-start mb-4">'+'<div class="img_cont_msg">'+image2a+'</div>'+'<div class="msg_cotainer">'+objecttext+'</div>'+'</div>'
		document.querySelector('#body').innerHTML+= botHtml;
		const listener = new THREE.AudioListener();
		camera.add( listener );
		const sound = new THREE.Audio( listener );
		const audioLoader = new THREE.AudioLoader();
		audioLoader.load( `{{ site.apilink2 }}${objecttext}`, function( buffer ) {
		sound.setBuffer( buffer );
		sound.setLoop( false );
		sound.setVolume( 0.5 );
		sound.play();
		const analyser1 = new THREE.AudioAnalyser( sound, 32 );
		}); 
		analyser = new THREE.AudioAnalyser( sound, 32 );
		const data5 = analyser.getAverageFrequency();
		console.log( analyser1.data);
		};
		
		}
	};
	var fd=new FormData();
	fd.append("file",blob, filename);
	var xhr=new XMLHttpRequest();
	xhr.open("POST","{{ site.apilink3 }}",true);
	xhr.setRequestHeader('Access-Control-Allow-Origin', '*');
	xhr.setRequestHeader("Access-Control-Allow-Methods","PUT, GET, POST, DELETE, OPTIONS");
	xhr.setRequestHeader("Access-Control-Allow-Headers","Special-Request-Header, Origin, X-Requested-With, Content-Type, Accept, Authorization");
	xhr.setRequestHeader('Access-Control-Allow-Credentials', 'true');
	xhr.setRequestHeader('Access-Control-Max-Age', '240');
	xhr.send(fd);
	/*
e.target.responseText
	*/
	

	upload.addEventListener("click", function(event){
		  var xhr=new XMLHttpRequest();
		  xhr.onload=function(e) {
		      if(this.readyState === 4) {
		          console.log("Server returned: ",e.target.responseText);
		      }
		  };
		  var fd=new FormData();
		  fd.append("file",blob, filename);
		  xhr.open("POST","{{ site.apilink3 }}",true);
		  xhr.setRequestHeader('Access-Control-Allow-Origin', '*');
		  xhr.setRequestHeader("Access-Control-Allow-Methods","PUT, GET, POST, DELETE, OPTIONS");
		  xhr.setRequestHeader("Access-Control-Allow-Headers","Special-Request-Header, Origin, X-Requested-With, Content-Type, Accept, Authorization");
		  xhr.setRequestHeader('Access-Control-Allow-Credentials', 'true');
		  xhr.setRequestHeader('Access-Control-Max-Age', '240');
		  xhr.send(fd);
	})
	li.appendChild(document.createTextNode (" "))//add a space in between
	li.appendChild(upload)//add the upload link to li

	//add the li element to the ol
	recordingsList.appendChild(li);
}

playtrack.onclick = function playtrack1() {
let image2 = `<img src="/media/d1.jpg" class="rounded-circle user_img_msg">`;
const image1 = `{% include image2.html %}`;
let xhr = new XMLHttpRequest();
var userMessage = document.querySelector("#userInput").value;
let userHtml = '<div class="d-flex justify-content-end mb-4">'+'<div class="msg_cotainer_send">'+userMessage+'</div>'+image1+'</div>'
document.querySelector('#body').innerHTML+= userHtml;
xhr.open(`GET`, `{{ site.apilink1 }}${userMessage}`);
xhr.setRequestHeader("Content-type", "application/x-www-form-urlencoded");
xhr.send(`messageValue=${userMessage}`);
xhr.onload = function () {
var obj = JSON.parse(this.responseText);
console.log(JSON.stringify(obj.traits));
var objlength = JSON.stringify(obj.traits);
var obj1q = JSON.stringify(this.responseText);
if (objlength.length < 3) {
var objecttext = "I'm sorry, but I didn't understand the question. Please try again";
console.log(objecttext+'dfgdfgdfgdfgdgdgdgdgf'); 
}else { var objecttext = obj.traits.text[0].value};
let botHtml = '<div class="d-flex justify-content-start mb-4">'+'<div class="img_cont_msg">'+image2a+'</div>'+'<div class="msg_cotainer">'+objecttext+'</div>'+'</div>'
document.querySelector('#body').innerHTML+= botHtml;
const listener = new THREE.AudioListener();
camera.add( listener );
const sound = new THREE.Audio( listener );
const audioLoader = new THREE.AudioLoader();
audioLoader.load( `{{ site.apilink2 }}${objecttext}`, function( buffer ) {
sound.setBuffer( buffer );
sound.setLoop( false );
sound.setVolume( 0.5 );
sound.play();
const analyser1 = new THREE.AudioAnalyser( sound, 32 );
}); 
analyser = new THREE.AudioAnalyser( sound, 32 );
const data5 = analyser.getAverageFrequency();
console.log( analyser1.data);
};
};

window.addEventListener( 'resize', onWindowResize );

// stats
//stats = new Stats();
//container.appendChild( stats.dom );
controls.update();

}
function modifyTimeScale( speed ) {

mixer.timeScale = speed;

}


const gui = new GUI()
const folder1 = gui.addFolder('Base Actions');
const folder2 = gui.addFolder( 'Additive Action Weights' );
const folder3 = gui.addFolder( 'General Speed' );
const cameraFolder = gui.addFolder('Camera');
//folder2.add( 'dude', 0, 1);
cameraFolder.add(camera.position, 'z', 0, 300);
cameraFolder.add(camera.position, 'y', 0, 300);
cameraFolder.add(camera.position, 'x', 0, 300);


cameraFolder.open();
panelSettings = {
'modify time scale': 1.0
};

//gui.close();
gui.hide();



crossFadeControls.forEach( function ( control ) {

control.setInactive = function () {

control.domElement.classList.add( 'control-inactive' );

};

control.setActive = function () {

control.domElement.classList.remove( 'control-inactive' );

};

const settings = baseActions[ control.property ];

if ( ! settings || ! settings.weight ) {

control.setInactive();

}

} );



//const baseNames = [ 'None', ...Object.keys( baseActions ) ];
/*
for ( let i = 0, l = baseNames.length; i !== l; ++ i ) {

const name = baseNames[ i ];
const settings = baseActions[ name ];
panelSettings[ name ] = function () {

const currentSettings = baseActions[ currentBaseAction ];
const currentAction = currentSettings ? currentSettings.action : null;
const action = settings ? settings.action : null;

if ( currentAction !== action ) {

prepareCrossFade( currentAction, action, 0.35 );

}

};

crossFadeControls.push( folder1.add( panelSettings, name ) );

}

for ( const name of Object.keys( additiveActions ) ) {

const settings = additiveActions[ name ];

panelSettings[ name ] = settings.weight;
folder2.add( panelSettings, name, 0.0, 1.0, 0.01 ).listen().onChange( function ( weight ) {

setWeight( settings.action, weight );
settings.weight = weight;

} );



}
*/
folder3.add( panelSettings, 'modify time scale', 0.0, 1.5, 0.01 ).onChange( modifyTimeScale );

folder1.open();
folder2.open();
folder3.open();


function onWindowResize() {

camera.aspect = window.innerWidth / window.innerHeight;
camera.updateProjectionMatrix();

renderer.setSize( window.innerWidth, window.innerHeight );

}

function animate() {

requestAnimationFrame( animate );


const delta = clock.getDelta();

if ( mixer ) mixer.update( delta );

renderer.render( scene, camera );

//stats.update();

}


</script>

<div style="display: none;" id="soundClips"></div>
</body>

</html>
